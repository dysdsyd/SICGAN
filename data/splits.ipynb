{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/jiadeng_root/jiadeng/shared_data/datasets/SICGAN_data/'\n",
    "labels = {'04379243':'table','03211117':'monitor','04401088':'cellphone','04530566': 'watercraft',  '03001627' : 'chair','03636649' : 'lamp',  '03691459': 'speaker' ,  '02828884':'bench',\n",
    "'02691156': 'plane', '02808440': 'bathtub',  '02871439': 'bookcase',\n",
    "'02773838': 'bag', '02801938': 'basket', '02828884' : 'bench','02880940': 'bowl' ,\n",
    "'02924116': 'bus', '02933112': 'cabinet', '02942699': 'camera', '02958343': 'car', '03207941': 'dishwasher',\n",
    "'03337140': 'file', '03624134': 'knife', '03642806': 'laptop', '03710193': 'mailbox',\n",
    "'03761084': 'microwave', '03928116': 'piano', '03938244':'pillow', '03948459': 'pistol', '04004475': 'printer',\n",
    "'04099429': 'rocket', '04256520': 'sofa', '04554684': 'washer', '04090263': 'rifle'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = defaultdict(dict)\n",
    "for sid in ['03001627', '04379243']:\n",
    "    sid_pth = os.path.join(path, sid)\n",
    "    for mid in tqdm(os.listdir(sid_pth)):\n",
    "        mid_pth = os.path.join(sid_pth, mid)\n",
    "        image_list = os.listdir(os.path.join(mid_pth, 'images'))\n",
    "        summary[sid][mid] = len(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in summary:\n",
    "    print(sid,labels[sid]+' : '+str(len(set(summary[sid]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'summary.json', \"w\") as f:\n",
    "    json.dump(summary, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'summary.json', \"r\") as f:\n",
    "    summary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_file = defaultdict(dict)\n",
    "trn_ratio = 3500\n",
    "val_ratio = 4500\n",
    "tst_ratio = 5500\n",
    "for sid in summary:\n",
    "    sid_pth = os.path.join(path, sid)\n",
    "    sid_len = len(os.listdir(sid_pth))\n",
    "    for i,mid in enumerate(tqdm(os.listdir(sid_pth))):\n",
    "        if i < trn_ratio:\n",
    "            split_type = 'train'\n",
    "        elif i < val_ratio:\n",
    "            split_type = 'val'\n",
    "        elif i < tst_ratio:\n",
    "            split_type = 'test'\n",
    "        else:\n",
    "            split_type = 'leftover'\n",
    "        mid_pth = os.path.join(sid_pth, mid)\n",
    "        num_image = len(os.listdir(os.path.join(mid_pth, 'images')))\n",
    "        try:\n",
    "            split_file[split_type][sid].update({mid : [i for i in range(num_image)]})\n",
    "        except:\n",
    "            split_file[split_type][sid] = {}\n",
    "            split_file[split_type][sid].update({mid : [i for i in range(num_image)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "\tchair : 3500\n",
      "\ttable : 3500\n",
      "val\n",
      "\tchair : 1000\n",
      "\ttable : 1000\n",
      "test\n",
      "\tchair : 1000\n",
      "\ttable : 1000\n",
      "leftover\n",
      "\tchair : 11\n",
      "\ttable : 2177\n"
     ]
    }
   ],
   "source": [
    "for data in split_file:\n",
    "    print(data)\n",
    "    for sid in split_file[data]:\n",
    "        print('\\t'+labels[sid]+' : '+str(len(set(split_file[data][sid]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path+'p2m_splits.json', \"w\") as f:\n",
    "    json.dump(split_file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('p2m_splits.json', \"w\") as f:\n",
    "    json.dump(split_file, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(path+'p2m_splits.json', \"r\") as f:\n",
    "    split_file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os,sys\n",
    "from typing import Type\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "\n",
    "from sicgan.config import Config\n",
    "from sicgan.models import Pixel2MeshHead\n",
    "from sicgan.models import GraphConvClf\n",
    "from sicgan.data.build_data_loader import build_data_loader\n",
    "from sicgan.models import MeshLoss\n",
    "from sicgan.utils.torch_utils import save_checkpoint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_C = Config('config/train_p2m.yml', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataloader = build_data_loader(_C, \"MeshVox\", split_name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_file = _C.DATASETS.SPLITS_FILE\n",
    "split_name = 'test'\n",
    "with open(splits_file, \"r\") as f:\n",
    "    splits = json.load(f)\n",
    "if split_name is not None:\n",
    "    if split_name in [\"train\", \"train_eval\"]:\n",
    "        split = splits[\"train\"]\n",
    "    else:\n",
    "        split = splits[split_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import torch\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "from pytorch3d.structures import Meshes\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from sicgan.data.utils import imagenet_preprocess, project_verts\n",
    "# from shapenet.utils.coords import SHAPENET_MAX_ZMAX, SHAPENET_MIN_ZMIN, project_verts\n",
    "\n",
    "logger = logging.getLogger('mesh')\n",
    "\n",
    "\n",
    "class MeshVoxDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        normalize_images=True,\n",
    "        split=None,\n",
    "        return_mesh=False,\n",
    "        voxel_size=32,    # Not required\n",
    "        num_samples=5000,\n",
    "        sample_online=False,\n",
    "        in_memory=False,\n",
    "        return_id_str=False,\n",
    "    ):\n",
    "\n",
    "        super(MeshVoxDataset, self).__init__()\n",
    "        if not return_mesh and sample_online:\n",
    "            raise ValueError(\"Cannot sample online without returning mesh\")\n",
    "        self.data_dir = data_dir\n",
    "        self.return_mesh = return_mesh\n",
    "        # self.voxel_size = voxel_size\n",
    "        self.num_samples = num_samples\n",
    "        self.sample_online = sample_online\n",
    "        self.return_id_str = return_id_str\n",
    "        \n",
    "        self.synset_ids = []\n",
    "        self.model_ids = []\n",
    "        self.image_ids = []\n",
    "        self.mid_to_samples = {}\n",
    "\n",
    "        transform = [T.Resize((192,256))]\n",
    "        transform.append(T.ToTensor())\n",
    "        if normalize_images:\n",
    "            transform.append(imagenet_preprocess())   # Change this to r2n2 params\n",
    "        self.transform = T.Compose(transform)\n",
    "\n",
    "        summary_json = os.path.join(data_dir, \"summary.json\")\n",
    "        print(data_dir)\n",
    "        with open(summary_json, \"r\") as f:\n",
    "            summary = json.load(f)\n",
    "            for sid in summary:\n",
    "                print(\"Starting synset %s\" % sid)\n",
    "                allowed_mids = None\n",
    "                if split is not None:\n",
    "                    if sid not in split:\n",
    "                        print(\"Skipping synset %s\" % sid)\n",
    "                        continue\n",
    "                    elif isinstance(split[sid], list):\n",
    "                        print('list')\n",
    "                        allowed_mids = set(split[sid])\n",
    "                    elif isinstance(split, dict):\n",
    "                        print('dict')\n",
    "                        allowed_mids = set(split[sid].keys())\n",
    "                print(len(allowed_mids))\n",
    "#                 print(allowed_mids)\n",
    "                a = []\n",
    "                b = 0\n",
    "                for mid, num_imgs in summary[sid].items():\n",
    "                    a.append(mid not in allowed_mids)\n",
    "                    if allowed_mids is not None and mid not in allowed_mids:\n",
    "#                         print('skipping over : ', mid)\n",
    "#                         print(mid not in allowed_mids)\n",
    "                        continue\n",
    "                    allowed_iids = None\n",
    "                    if split is not None and isinstance(split[sid], dict):\n",
    "                        allowed_iids = set(split[sid][mid])\n",
    "                    if not sample_online and in_memory:\n",
    "                        samples_path = os.path.join(data_dir, sid, mid, \"samples.pt\")\n",
    "                        samples = torch.load(samples_path)\n",
    "                        self.mid_to_samples[mid] = samples\n",
    "                    for iid in range(num_imgs):\n",
    "                        if allowed_iids is None or iid in allowed_iids:\n",
    "                            b +=1\n",
    "                            self.synset_ids.append(sid)\n",
    "                            self.model_ids.append(mid)\n",
    "                            self.image_ids.append(iid)\n",
    "#                         else:\n",
    "#                             print(iid in allowed_iids, iid, allowed_iids)\n",
    "#                             break\n",
    "                print(np.sum(a),b)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.synset_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid = self.synset_ids[idx]\n",
    "        mid = self.model_ids[idx]\n",
    "        iid = self.image_ids[idx]\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/jiadeng_root/jiadeng/shared_data/datasets/SICGAN_data/\n",
      "Starting synset 03001627\n",
      "dict\n",
      "1000\n",
      "4511 24000\n",
      "Starting synset 04379243\n",
      "dict\n",
      "1000\n",
      "6677 24000\n"
     ]
    }
   ],
   "source": [
    "dset = MeshVoxDataset(\n",
    "    _C.DATASETS.DATA_DIR,\n",
    "    split=split,\n",
    "    num_samples=_C.G.MESH_HEAD.GT_NUM_SAMPLES,\n",
    "    return_mesh=True,\n",
    "    sample_online=False,\n",
    "    return_id_str=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dset)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "synset_ids = []\n",
    "model_ids = []\n",
    "image_ids = []\n",
    "mid_to_samples = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/jiadeng_root/jiadeng/shared_data/datasets/SICGAN_data/\n",
      "Starting synset 03001627\n",
      "dict\n",
      "1000\n",
      "1000 24000\n",
      "Starting synset 04379243\n",
      "dict\n",
      "1000\n",
      "1000 24000\n"
     ]
    }
   ],
   "source": [
    "data_dir = _C.DATASETS.DATA_DIR\n",
    "summary_json = os.path.join(data_dir, \"summary.json\")\n",
    "print(data_dir)\n",
    "with open(summary_json, \"r\") as f:\n",
    "    summary = json.load(f)\n",
    "    for sid in summary:\n",
    "        print(\"Starting synset %s\" % sid)\n",
    "        allowed_mids = None\n",
    "        if split is not None:\n",
    "            if sid not in split:\n",
    "                print(\"Skipping synset %s\" % sid)\n",
    "                continue\n",
    "            elif isinstance(split[sid], list):\n",
    "                print('list')\n",
    "                allowed_mids = set(split[sid])\n",
    "            elif isinstance(split, dict):\n",
    "                print('dict')\n",
    "                allowed_mids = set(split[sid].keys())\n",
    "        print(len(allowed_mids))\n",
    "        a = []\n",
    "        b = 0\n",
    "        for mid, num_imgs in summary[sid].items():\n",
    "            if allowed_mids is not None and mid not in allowed_mids:\n",
    "    #                         print('skipping over : ', mid)\n",
    "    #                         print(mid not in allowed_mids)\n",
    "                continue\n",
    "            else:\n",
    "                a.append(mid)\n",
    "            allowed_iids = None\n",
    "            if split is not None and isinstance(split[sid], dict):\n",
    "                allowed_iids = set(split[sid][mid])\n",
    "            for iid in range(num_imgs):\n",
    "                if allowed_iids is None or iid in allowed_iids:\n",
    "                    b +=1\n",
    "                    synset_ids.append(sid)\n",
    "                    model_ids.append(mid)\n",
    "                    image_ids.append(iid)\n",
    "    #                         else:\n",
    "    #                             print(iid in allowed_iids, iid, allowed_iids)\n",
    "    #                             break\n",
    "        print(len(a),b)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0 \n",
    "a = 0\n",
    "m =[]\n",
    "for mid, num_imgs in summary[sid].items():\n",
    "    a+=1\n",
    "    if allowed_mids is not None and mid not in allowed_mids:\n",
    "        b+=1\n",
    "    else:\n",
    "        m.append(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mid, num_imgs in summary[sid].items():\n",
    "    print(mid, num_imgs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_mids = set(split[sid].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid in allowed_mids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sicgan.models import MeshLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyGEL3D import gel\n",
    "from PyGEL3D import js\n",
    "import re\n",
    "from pytorch3d.io import load_obj, save_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sicgan.models import Pixel2MeshHead\n",
    "from sicgan.config import Config\n",
    "\n",
    "\n",
    "_C = Config('./config/sicgan_train.yml', [])\n",
    "G = Pixel2MeshHead(_C).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sicgan.data.build_data_loader import build_data_loader\n",
    "train = build_data_loader(_C, \"MeshVox\", split_name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in tqdm(train):\n",
    "    imgs = data[0]\n",
    "    meshes = data[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(imgs[2].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mesh(mesh):\n",
    "    save_obj('mesh.obj', mesh.verts_packed(), mesh.faces_packed())\n",
    "    js.set_export_mode()\n",
    "    m = gel.obj_load('mesh.obj')\n",
    "    js.display(m, smooth=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot_mesh(i[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = G(imgs.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sicgan.models import GraphConvClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = GraphConvClf(_C).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "D(m.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    loss_fn_kwargs = {\n",
    "        \"chamfer_weight\": _C.G.MESH_HEAD.CHAMFER_LOSS_WEIGHT,\n",
    "        \"normal_weight\": _C.G.MESH_HEAD.NORMAL_LOSS_WEIGHT,\n",
    "        \"edge_weight\": _C.G.MESH_HEAD.EDGE_LOSS_WEIGHT,\n",
    "        \"gt_num_samples\": _C.G.MESH_HEAD.GT_NUM_SAMPLES,\n",
    "        \"pred_num_samples\": _C.G.MESH_HEAD.PRED_NUM_SAMPLES,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_loss = MeshLoss(**loss_fn_kwargs).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_loss(m.cuda(), meshes.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
